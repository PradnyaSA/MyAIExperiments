{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**README**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## About the notebook\n",
        "\n",
        "This notebook demonstrates a Prompt Engineering technique called **Chain-Of-Thought(CoT)** prompting. It shows how CoT prompting enhances an AI model's ability to solve complex, multi-step problems.<br>\n",
        "\n",
        "\n",
        "\n",
        "*Pre-requisites:* To run this notebook,\n",
        "\n",
        "- Refer to [Google Colab](https://colab.research.google.com/) to get started instantly, for *free* !\n",
        "\n",
        "- Download and open this notebook in Google Colab.\n",
        "\n",
        "- Get your access key to the [OpenAI](https://platform.openai.com/account/api-keys) API.<br>\n",
        "\n",
        "- Set up this access key under *secrets* in your Google Colab runtime environment.\n",
        "\n",
        "- You are all set! Have fun!\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Topic: Chain-Of-Thought Prompting\n",
        "\n",
        "Evolving models with sophisticated reasoning abilities thrive on techniques such as Chain-of-Thought(CoT), few-shot prompting.<br>\n",
        "\n",
        "CoT prompting technique enables complex reasoning capabilities through intermediate reasoning steps.<br>\n",
        "\n",
        "\n",
        "\n",
        "Let's look at an example of a mathematical question where CoT prompting takes the center stage:<br>\n",
        "\n",
        "```\n",
        "\n",
        "\"A customer servicing agent needs 10 minutes of talk time for each complex customer inquiry. How many minutes will 120 customer service agents need in a year, if each agent handles 10 complex inquiries per day? If each customer servicing agent saves 1 minute for each complex customer inquiry, how many minutes will be saved in a year?\"\n",
        "\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "**Without CoT:** Adding extra information to a zero-shot prompt can force even the general-purpose model to think-out-loud before generating a response *OR* adding examples like few-shot prompting can make the general-purpose model split the task into multiple steps.<br>\n",
        "\n",
        "\n",
        "\n",
        "**With CoT:** Setting a high reasoning effort can make an evolved, better reasoning model potentially generate more detailed and accurate CoT responses without any further instructions.<br><br>\n",
        "\n",
        "\n",
        "\n",
        "What do you think the responses with CoT would be? Let's find out!\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "fC-NxhKbRHOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hands-on exercise using OpenAI API.\n",
        "# This is to showcase how CoT enables an AI model to articulate its reasoning behind the generated response, improving transparency."
      ],
      "metadata": {
        "id": "aA98r6bSg5ui"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About this excercise:\n",
        "</br>\n",
        "\n",
        "|Category|Description|\n",
        "|:--|:--|\n",
        "|Task |Solve a mathematical calculation problem step-by-step|\n",
        "|Difficuly Level|Beginner|\n",
        "|Skills|Python|\n",
        "</br>"
      ],
      "metadata": {
        "id": "t5fX29goEYf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import display and Markdown from IPython for formatted rendering of generated response\n",
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "tOBg13jg816S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ],
      "metadata": {
        "id": "g4Ox90irebfo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access setup - This function allows secure access to user-defined secrets stored in the Colab environment, such as API keys."
      ],
      "metadata": {
        "id": "FSAEuTOnSndK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "NL9XsB60uMzL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import - interact with the OpenAI API, allows us to make requests to models"
      ],
      "metadata": {
        "id": "FM78qcTOSOdK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VXpCYVk5uGDG"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure Access Key - in this exmpale, for open api. </br>\n",
        "How to configure API access keys in Colab:\n",
        "\n",
        "1. Go to the \"ðŸ”‘\" icon in the left sidebar (Secrets).\n",
        "2. Click \"Add new secret\".\n",
        "3. For the name, use 'openai_api_key'.\n",
        "4. For the value, paste your OpenAI API key.\n",
        "5. Make sure \"Notebook access\" is enabled for this secret.\n"
      ],
      "metadata": {
        "id": "7YmYmdejTN36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=userdata.get('openai_api_key'))"
      ],
      "metadata": {
        "id": "v8tFQuE3uNLQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attempt 1:** Add some extra information to the zero-shot prompt to force the model to think-out-loud before generating a response (in CoT style)."
      ],
      "metadata": {
        "id": "VkRhL7yEwyQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"A customer servicing agent needs 10 minutes of talk time for each complex customer inquiry. How many minutes will 120 customer servicing agents need in a year, if each agent is handling 10 complex inquiries per day?\""
      ],
      "metadata": {
        "id": "Dndyy04srTkB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message += \"If each customer servicing agent saves 1 minute for each complex customer inquiry, how many minutes will be saved in a year?\" #an additional detail to a zero-shot prompt."
      ],
      "metadata": {
        "id": "rcZ3YxU86Vdd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_simple = client.responses.create(\n",
        "    model='gpt-4',\n",
        "    input=message,\n",
        "    max_output_tokens=2480\n",
        ")"
      ],
      "metadata": {
        "id": "tciPs-iYG0ja"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the response generated by AI model for a given prompt"
      ],
      "metadata": {
        "id": "ulb4jh5SxBMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "about_this_print='Following is how the generic model responds with an additional detail added to a zero-shot prompt:'\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div><br>' % about_this_print)\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div>' % response_simple.output_text)"
      ],
      "metadata": {
        "id": "Q1ys6iR7HyLf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "7db4c05a-a715-4338-8727-4402d8fad506"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">Following is how the generic model responds with an additional detail added to a zero-shot prompt:</div><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">First of all, we need to calculate how many minutes each agent spends daily on customer inquiries. Each inquiry takes 10 minutes and they handle 10 per day, so:\n\n10 minutes/inquiry * 10 inquiries/day = 100 minutes/day\n\nThen, we calculate the annual minutes spent by a single agent:\n\n100 minutes/day * 365 days/year = 36,500 minutes/year\n\nFor 120 agents, the total time spent in a year would be:\n\n36,500 minutes/year * 120 agents = 4,380,000 minutes/year\n\nIf each agent saves 1 minute for each inquiry, the saving per agent per day would be:\n\n1 minute/inquiry * 10 inquiries/day = 10 minutes/day\n\nThen, we calculate the annual savings for a single agent:\n\n10 minutes/day * 365 days/year = 3,650 minutes/year\n\nFor 120 agents, the total annual time saving would be:\n\n3,650 minutes/year * 120 agents = 438,000 minutes/year.</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attempt 2:** Add examples like few-shot prompting so the model learns from examples and splits the task into multiple steps (in CoT style)"
      ],
      "metadata": {
        "id": "ShyOPBVixpUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_manual_cot = client.responses.create(\n",
        "    model='gpt-4',\n",
        "    instructions=\"You are a helpful assistant. You must answer in a warm, polite, and friendly way like you are talking to a 20 years old.\",\n",
        "    input=[\n",
        "            {\"role\": \"system\", \"content\": \"\"\"\n",
        "            You are a helpful assistant.\n",
        "\n",
        "            Below are examples of questions and how to calculate the answer\n",
        "\n",
        "              Example 1: Arithmetic Problem\n",
        "              Prompt: \"If a toy costs $20 and there is a 10% discount, how much does the toy cost after the discount?\"\n",
        "              Chain of Thought Answer:\n",
        "                Calculate the amount of discount: 10% of $20 is $2.\n",
        "                Subtract the discount from the original price: $20 - $2 = $18.\n",
        "                The toy costs $18 after the discount.\n",
        "\n",
        "              Example 2: Logic Puzzle\n",
        "              Prompt: \"There are four apples and you take away three. How many apples do you have?\"\n",
        "              Chain of Thought Answer:\n",
        "                You start with four apples.\n",
        "                You take away three apples.\n",
        "                After taking three, you now have those three apples.\n",
        "                You have 3 apples\n",
        "\n",
        "              \"\"\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Answer the following question: {message}\"}\n",
        "        ],\n",
        "    max_output_tokens=2480\n",
        ")"
      ],
      "metadata": {
        "id": "bWkkGy5yZPet"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_this_print='Following is how the generic model responds with added few-shots to prompt:'\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div><br>' % about_this_print)\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div>' % response_manual_cot.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "uytJB4R3Z20y",
        "outputId": "a712fa2b-8858-410f-ed4c-2fe3334c7e82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">Following is how the generic model responds with added few-shots to prompt:</div><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">Alright, let's break this down together! \n\nFirstly, if one complex customer inquiry requires 10 minutes talk time for one customer service agent, and each agent is handling 10 complex inquiries per day, it means each agent spends: 10 minutes * 10 inquiries = 100 minutes per day. \n\nIf there are 120 customer service agents, their total talk time per day will be: 120 agents * 100 minutes = 12,000 minutes.\n\nWe know there are 365 days in a year, so, 12,000 minutes/day * 365 days/year = 4,380,000 minutes/year will be spent handling complex inquiries by all agents.\n\nNow, if each customer servicing agent saves 1 minute for each complex customer inquiry, each agent will save: 10 inquiries * 1 minute = 10 minutes per day.\n\nMultiply this by the number of agents (120) to get a total time saved daily by all agents: 10 minutes/agent/day * 120 agents = 1,200 minutes/day.\n\nTo find out the total time saved in a year, we can multiply this by the number of days in a year: 1,200 minutes/day * 365 days/year = 438,000 minutes/year.\n\nTherefore, if each customer servicing agent saves 1 minute for each complex customer inquiry, they will save a total of 438,000 minutes in a year.</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attempt 3:** Set reasoning effort to high, so the model articulates the reasoning in CoT style and provides a more accurate CoT response."
      ],
      "metadata": {
        "id": "bT4-kkxZaBpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_auto_cot = client.responses.create(\n",
        "    model='o4-mini', #a smaller model optimized for fast, cost-efficient reasoning, capable of processing both text and images\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"Think step-by-step to solve the problem.\"},\n",
        "        {\"role\": \"user\", \"content\": message}\n",
        "    ],\n",
        "    reasoning={\"effort\": \"high\"},\n",
        "    max_output_tokens=5000,\n",
        "    stream=False\n",
        ")"
      ],
      "metadata": {
        "id": "t_PoApy7uPbY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the response generated by AI model for a given prompt"
      ],
      "metadata": {
        "id": "6lVSke2kyAk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "about_this_print='Following is how the evolved reasoning model responds to a CoT prompt:'\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div><br>' % about_this_print)\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div>' % response_auto_cot.output_text)"
      ],
      "metadata": {
        "id": "5CnMi0TFud6k",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "c4010c8c-043a-4ba9-d3f2-195a65a8d663"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">Following is how the evolved reasoning model responds to a CoT prompt:</div><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">Letâ€™s assume each agent works every day of the year (365 days).  \n\n1. Minutes per agent per day  \n   = 10 inquiries/day Ã— 10 min/inquiry  \n   = 100 min/day  \n\n2. Minutes all 120 agents need per day  \n   = 120 agents Ã— 100 min/agent  \n   = 12 000 min/day  \n\n3. Annual talk time required  \n   = 12 000 min/day Ã— 365 days  \n   = 4 380 000 min/year  \n   â‰ƒ 73 000 hours/year  \n\n4. Annual time saved if each inquiry is 1 min faster  \n   â€“ Number of inquiries per year  \n     = 120 agents Ã— 10 inq/day Ã— 365 days  \n     = 438 000 inq/year  \n   â€“ Minutes saved  \n     = 438 000 inq Ã— 1 min/inquiry  \n     = 438 000 min/year  \n     â‰ƒ 7 300 hours/year  \n\nâ€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“  \nIf instead you count only 250 working days/year, you get:  \nâ€¢ Required = 12 000 min/day Ã— 250 days = 3 000 000 min  \nâ€¢ Saved    = (120Ã—10Ã—250)Ã—1 = 300 000 min.</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##Congratulations on running this fun exercise!\n",
        "\n",
        "\n",
        "CoT prompting enables the AI model to articulate reasoning, making it visible to the user and helping build confidence. The experience quality of working with AI improves, and this technique extends easily across domains for complex tasks, generating more accurate CoT responses. You just proved it yourself!<br>\n",
        "\n",
        "\n",
        "**Fun Fact:** Did you notice, we chose different models to show the difference in results?<br>\n",
        "\n",
        "**Extra Credit:** Try variations on effort and observe different responses. <br>\n",
        "\n",
        "**Pro Tip:** The true power of CoT is better realized when combined with other techniques like *few-shot* prompting. Don't forget the cost optimization benefit either!<br><br>\n",
        "\n",
        "If you are an AI Enthusiast, don't stop here - you could start with your first, simple chatbot application based on CoT. Try CoT prompting today!<br>"
      ],
      "metadata": {
        "id": "LTIH5nRkx4b5"
      }
    }
  ]
}