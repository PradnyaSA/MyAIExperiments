{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**README**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## About the notebook\n",
        "\n",
        "This notebook demonstrates a Prompt Engineering technique called **Chain-Of-Thought(CoT)** prompting. It shows how CoT prompting enhances an AI model's ability to solve complex, multi-step problems.<br>\n",
        "\n",
        "\n",
        "\n",
        "*Pre-requisites:* To run this notebook,\n",
        "\n",
        "- Refer to [Google Colab](https://colab.research.google.com/) to get started instantly, for *free* !\n",
        "\n",
        "- Download and open this notebook in Google Colab.\n",
        "\n",
        "- Get your access key to the [OpenAI](https://platform.openai.com/account/api-keys) API to run this notebook.<br>\n",
        "\n",
        "- Set up this access key under *secrets* in your Google Colab runtime environment.\n",
        "\n",
        "- You are all set! Have fun!\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Topic: Chain-Of-Thought Prompting\n",
        "\n",
        "Evolving models with sophisticated reasoning abilities thrive on techniques such as Chain-of-Thought(CoT), few-shot prompting.<br>\n",
        "\n",
        "CoT prompting technique enables complex reasoning capabilities through intermediate reasoning steps.<br>\n",
        "\n",
        "\n",
        "\n",
        "Let's look at an example of a mathematical question where CoT prompting takes the center stage:<br>\n",
        "\n",
        "```\n",
        "\n",
        "\"A customer servicing agent needs 10 minutes of talk time for each complex customer inquiry. How many minutes will 120 customer service agents need in a year, if each agent handles 10 complex inquiries per day? If each customer servicing agent saves 1 minute for each complex customer inquiry, how many minutes will be saved in a year?\"\n",
        "\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "**Without CoT:** Adding extra information to a zero-shot prompt can force even the general-purpose model to think-out-loud before generating a response *OR* adding examples like few-shot prompting can make the general-purpose model split the task into multiple steps.<br>\n",
        "\n",
        "\n",
        "\n",
        "**With CoT:** Setting a high reasoning effort can make an evolved, better reasoning model potentially generate more detailed and accurate CoT responses without any further instructions.<br><br>\n",
        "\n",
        "\n",
        "\n",
        "What do you think the responses with CoT would be? Let's find out!\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "fC-NxhKbRHOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hands-on exercise using OpenAI API.\n",
        "# This is to showcase how CoT enables an AI model to articulate its reasoning behind the generated response, improving transparency."
      ],
      "metadata": {
        "id": "aA98r6bSg5ui"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About this excercise:\n",
        "</br>\n",
        "\n",
        "|Category|Description|\n",
        "|:--|:--|\n",
        "|Task |Solve a mathematical calculation problem step-by-step|\n",
        "|Difficuly Level|Beginner|\n",
        "|Skills|Python|\n",
        "</br>"
      ],
      "metadata": {
        "id": "t5fX29goEYf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import display and Markdown from IPython for formatted rendering of generated response\n",
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "tOBg13jg816S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ],
      "metadata": {
        "id": "g4Ox90irebfo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access setup - This function allows secure access to user-defined secrets stored in the Colab environment, such as API keys."
      ],
      "metadata": {
        "id": "FSAEuTOnSndK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "NL9XsB60uMzL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import - interact with the OpenAI API, allows us to make requests to models"
      ],
      "metadata": {
        "id": "FM78qcTOSOdK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VXpCYVk5uGDG"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure Access Key - in this exmpale, for open api. </br>\n",
        "How to configure API access keys in Colab:\n",
        "\n",
        "1. Go to the \"ðŸ”‘\" icon in the left sidebar (Secrets).\n",
        "2. Click \"Add new secret\".\n",
        "3. For the name, use 'openai_api_key'.\n",
        "4. For the value, paste your OpenAI API key.\n",
        "5. Make sure \"Notebook access\" is enabled for this secret.\n"
      ],
      "metadata": {
        "id": "7YmYmdejTN36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=userdata.get('openai_api_key'))"
      ],
      "metadata": {
        "id": "v8tFQuE3uNLQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attempt 1:** Add some extra information to the zero-shot prompt to force the model to think-out-loud before generating a response (in CoT style)."
      ],
      "metadata": {
        "id": "VkRhL7yEwyQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"A customer servicing agent needs 10 minutes of talk time for each complex customer inquiry. How many minutes will 120 customer servicing agents need in a year, if each agent is handling 10 complex inquiries per day?\""
      ],
      "metadata": {
        "id": "Dndyy04srTkB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message += \"If each customer servicing agent saves 1 minute for each complex customer inquiry, how many minutes will be saved in a year?\" #an additional detail to a zero-shot prompt."
      ],
      "metadata": {
        "id": "rcZ3YxU86Vdd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_simple = client.responses.create(\n",
        "    model='gpt-4',\n",
        "    input=message,\n",
        "    max_output_tokens=2480\n",
        ")"
      ],
      "metadata": {
        "id": "tciPs-iYG0ja"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the response generated by AI model for a given prompt"
      ],
      "metadata": {
        "id": "ulb4jh5SxBMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "about_this_print='Following is how the generic model responds with an additional detail added to a zero-shot prompt:'\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div><br>' % about_this_print)\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div>' % response_simple.output_text)"
      ],
      "metadata": {
        "id": "Q1ys6iR7HyLf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "3bac65f9-16a1-429f-e870-8f83114f8f00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">Following is how the generic model responds with an additional detail added to a zero-shot prompt:</div><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">First, let's calculate how many minutes a customer servicing agent spends a day on complex inquiries:\n10 minutes/inquiry x 10 inquiries/day = 100 minutes/day\n\nIf we have 120 agents, the total amount of minutes spent a day is:\n100 minutes/day/agent x 120 agents = 12000 minutes/day\n\nThere are 365 days in a year, so if these agents are working every day, they will spend:\n12000 minutes/day x 365 days/year = 4,380,000 minutes/year\n\nIf each customer servicing agent saves 1 minute for each complex customer inquiry, they save:\n1 minute/inquiry x 10 inquiries/day = 10 minutes/day\n\nMultiple this by the number of agents and days in a year, they will save:\n10 minutes/day/agent x 120 agents x 365 days/year = 438,000 minutes/year</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attempt 2:** Add examples like few-shot prompting so the model learns from examples and splits the task into multiple steps (in CoT style)"
      ],
      "metadata": {
        "id": "ShyOPBVixpUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_manual_cot = client.responses.create(\n",
        "    model='gpt-4',\n",
        "    instructions=\"You are a helpful assistant. You must answer in a warm, polite, and friendly way like you are talking to a 20 years old.\",\n",
        "    input=[\n",
        "            {\"role\": \"system\", \"content\": \"\"\"\n",
        "            You are a helpful assistant.\n",
        "\n",
        "            Below are examples of questions and how to calculate the answer\n",
        "\n",
        "              Example 1: Arithmetic Problem\n",
        "              Prompt: \"If a toy costs $20 and there is a 10% discount, how much does the toy cost after the discount?\"\n",
        "              Chain of Thought Answer:\n",
        "                Calculate the amount of discount: 10% of $20 is $2.\n",
        "                Subtract the discount from the original price: $20 - $2 = $18.\n",
        "                The toy costs $18 after the discount.\n",
        "\n",
        "              Example 2: Logic Puzzle\n",
        "              Prompt: \"There are four apples and you take away three. How many apples do you have?\"\n",
        "              Chain of Thought Answer:\n",
        "                You start with four apples.\n",
        "                You take away three apples.\n",
        "                After taking three, you now have those three apples.\n",
        "                You have 3 apples\n",
        "\n",
        "              \"\"\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Answer the following question: {message}\"}\n",
        "        ],\n",
        "    max_output_tokens=2480\n",
        ")"
      ],
      "metadata": {
        "id": "bWkkGy5yZPet"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_this_print='Following is how the generic model responds with added few-shots to prompt:'\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div><br>' % about_this_print)\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div>' % response_manual_cot.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "uytJB4R3Z20y",
        "outputId": "2e815a44-671f-40b0-c61a-c66d792ff2df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">Following is how the generic model responds with added few-shots to prompt:</div><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">To calculate the total minutes per year, we first need to work on the daily minutes. If each agent spends 10 minutes for each inquiry, and they handle 10 inquiries each day, each agent will spend 100 minutes each day (10 minutes * 10).\n\nNow, let's figure out the total daily minutes for all 120 agents. We simply multiply the daily time of one agent by the total number of agents, so that would be 100 minutes per agent * 120 agents = 12,000 minutes per day.\n\nIn a year, with the average number of working days being considered as 260 days (52 weeks * 5 working days), total minutes will be 12,000 minutes per day * 260 = 3,120,000 minutes a year.\n\nNow, if each agent saves one minute per each complex inquiry, the saving is 1 minute * 10 inquiries per day = 10 minutes saved per day per agent.\n\nSo, for all 120 agents, they would save 10 minutes * 120 agents = 1,200 minutes per day.\n\nOver the course of a year, these agents would save 1,200 minutes per day * 260 = 312,000 minutes in a year.\n\nThere you go! It's pretty fascinating what a minute saved can do over the long haul, isn't it?</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attempt 3:** Set reasoning effort to high, so the model articulates the reasoning in CoT style and provides a more accurate CoT response."
      ],
      "metadata": {
        "id": "bT4-kkxZaBpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_auto_cot = client.responses.create(\n",
        "    model='o4-mini', #a smaller model optimized for fast, cost-efficient reasoning, capable of processing both text and images\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"Think step-by-step to solve the problem.\"},\n",
        "        {\"role\": \"user\", \"content\": message}\n",
        "    ],\n",
        "    reasoning={\"effort\": \"high\"},\n",
        "    max_output_tokens=5000,\n",
        "    stream=False\n",
        ")"
      ],
      "metadata": {
        "id": "t_PoApy7uPbY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the response generated by AI model for a given prompt"
      ],
      "metadata": {
        "id": "6lVSke2kyAk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "about_this_print='Following is how the evolved reasoning model responds to a CoT prompt:'\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div><br>' % about_this_print)\n",
        "printmd('<div style=\"background-color: lightblue; padding: 10px;\">%s</div>' % response_auto_cot.output_text)"
      ],
      "metadata": {
        "id": "5CnMi0TFud6k",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "416e1158-3654-4f68-cf4f-d86d98603861"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">Following is how the evolved reasoning model responds to a CoT prompt:</div><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<div style=\"background-color: lightblue; padding: 10px;\">Step 1: Compute daily talk-time per agent  \nâ€“ 10 complex inquiries/day Ã— 10 minutes/inquiry = 100 minutes/day  \n\nStep 2: Compute total daily talk-time for 120 agents  \nâ€“ 120 agents Ã— 100 minutes/day = 12 000 minutes/day  \n\nStep 3: Scale to a full year (365 days)  \nâ€“ 12 000 minutes/day Ã— 365 days = 4 380 000 minutes/year  \n\nSo, in one year they need 4 380 000 minutes of talk time.  \n\nStep 4: Compute daily minutes saved per agent  \nâ€“ 10 inquiries/day Ã— 1 minute saved/inquiry = 10 minutes saved/day  \n\nStep 5: Total daily savings for 120 agents  \nâ€“ 120 agents Ã— 10 minutes/day = 1 200 minutes saved/day  \n\nStep 6: Scale to a full year  \nâ€“ 1 200 minutes/day Ã— 365 days = 438 000 minutes saved/year  \n\nAnswer:  \nâ€¢ Total annual talk time = 4 380 000 minutes  \nâ€¢ Total annual minutes saved = 438 000 minutes</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##Congratulations on running this fun exercise!\n",
        "\n",
        "\n",
        "CoT prompting enables the AI model to articulate reasoning, making it visible to the user and helping build confidence. The experience quality of working with AI improves, and this technique extends easily across domains for complex tasks, generating more accurate CoT responses. You just proved it yourself!<br>\n",
        "\n",
        "\n",
        "**Fun Fact:** Did you notice, we chose different models to show the difference in results?<br>\n",
        "\n",
        "**Extra Credit:** Try variations on effort and observe different responses. <br>\n",
        "\n",
        "**Pro Tip:** The true power of CoT is better realized when combined with other techniques like *few-shot* prompting. Don't forget the cost optimization benefit either!<br><br>\n",
        "\n",
        "If you are an AI Enthusiast, don't stop here - you could start with your first, simple chatbot application based on CoT. Try CoT prompting today!<br>"
      ],
      "metadata": {
        "id": "LTIH5nRkx4b5"
      }
    }
  ]
}